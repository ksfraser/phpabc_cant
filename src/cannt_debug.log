TokenNormalizer: token='{g}A3' normalized='{g}A'
TokenNormalizer: token='{g}B2' normalized='{g}B'
TokenNormalizer: token='{g}X3' normalized='{g'
TokenNormalizer: token='A' normalized='A'
TokenNormalizer: token='B' normalized='B'
TokenNormalizer: token='C' normalized='C'
TokenNormalizer: token='A' normalized='A'
TokenNormalizer: token='A' normalized='A'
TokenNormalizer: token='A' normalized='A'
TokenNormalizer: token='X' normalized='X'
TokenNormalizer: token='B' normalized='B'
TokenNormalizer: token='A' normalized='A'
TokenNormalizer: token='B' normalized='B'
TokenNormalizer: token='C' normalized='C'
TokenNormalizer: token='A' normalized='A'
TokenNormalizer: token='A' normalized='A'
TokenNormalizer: token='A' normalized='A'
TokenNormalizer: token='X' normalized='X'
TokenNormalizer: token='B' normalized='B'
TokenNormalizer: token='{g}A3' normalized='{g}A'
TokenNormalizer: token='{g}B2' normalized='{g}B'
TokenNormalizer: token='{d}c1' normalized='{d}c'
TokenNormalizer: token='A4' normalized='A'
TokenNormalizer: token='|' normalized='|'
TokenNormalizer: token='||' normalized='||'
TokenNormalizer: token='{g}A3' normalized='{g}A'
TokenNormalizer: token='X' normalized='X'
TokenNormalizer: token='B' normalized='B'
TokenNormalizer: token='{g}A3' part='{g}A3' normalized='{g}A'
TokenNormalizer: token='{g}B2' part='{g}B2' normalized='{g}B'
TokenNormalizer: token='{d}c1' part='{d}c1' normalized='{d}c'
TokenNormalizer: token='A4' part='A4' normalized='A'
TokenNormalizer: token='{g}A3' part='{g}A3' normalized='{g}A'
TokenToCanntMapper: token='{g}A3' normalized='{g}A'
TokenToCanntMapper: MAPPED '{g}A' => 'hen'
TokenNormalizer: token='{g}B2' part='{g}B2' normalized='{g}B'
TokenToCanntMapper: token='{g}B2' normalized='{g}B'
TokenToCanntMapper: MAPPED '{g}B' => 'o'
TokenNormalizer: token='{d}c1' part='{d}c1' normalized='{d}c'
TokenToCanntMapper: token='{d}c1' normalized='{d}c'
TokenToCanntMapper: MAPPED '{d}c' => 'do'
TokenNormalizer: token='{g}X3' part='g' normalized='g'
TokenToCanntMapper: token='{g}X3' normalized='g'
TokenToCanntMapper: NO MAPPING for 'g'
TokenNormalizer: token='{g}A3' part='{g}A3' normalized='{g}A'
TokenNormalizer: token='{g}B2' part='{g}B2' normalized='{g}B'
TokenNormalizer: token='{g}X3' part='g' normalized='g'
TokenNormalizer: token='{g}A3' part='{g}A3' normalized='{g}A'
TokenNormalizer: token='{g}B2' part='{g}B2' normalized='{g}B'
TokenNormalizer: token='{d}c1' part='{d}c1' normalized='{d}c'
TokenNormalizer: token='A4' part='A4' normalized='A'
TokenNormalizer: token='{g}A3' part='{g}A3' normalized='{g}A'
TokenToCanntMapper: token='{g}A3' normalized='{g}A'
TokenToCanntMapper: MAPPED '{g}A' => 'hen'
TokenNormalizer: token='{g}B2' part='{g}B2' normalized='{g}B'
TokenToCanntMapper: token='{g}B2' normalized='{g}B'
TokenToCanntMapper: MAPPED '{g}B' => 'o'
TokenNormalizer: token='{d}c1' part='{d}c1' normalized='{d}c'
TokenToCanntMapper: token='{d}c1' normalized='{d}c'
TokenToCanntMapper: MAPPED '{d}c' => 'do'
TokenNormalizer: token='{g}X3' part='g' normalized='g'
TokenToCanntMapper: token='{g}X3' normalized='g'
TokenToCanntMapper: NO MAPPING for 'g'
TokenNormalizer: token='{g}A3' part='{g}A3' normalized='{g}A'
TokenNormalizer: token='{g}B2' part='{g}B2' normalized='{g}B'
TokenNormalizer: token='{d}c1' part='{d}c1' normalized='{d}c'
TokenNormalizer: token='A4' part='A4' normalized='A'
TokenNormalizer: token='{g}A3' part='{g}A3' normalized='{g}A'
TokenToCanntMapper: token='{g}A3' normalized='{g}A'
TokenToCanntMapper: MAPPED '{g}A' => 'hen'
TokenNormalizer: token='{g}B2' part='{g}B2' normalized='{g}B'
TokenToCanntMapper: token='{g}B2' normalized='{g}B'
TokenToCanntMapper: MAPPED '{g}B' => 'o'
TokenNormalizer: token='{d}c1' part='{d}c1' normalized='{d}c'
TokenToCanntMapper: token='{d}c1' normalized='{d}c'
TokenToCanntMapper: MAPPED '{d}c' => 'do'
TokenNormalizer: token='{g}X3' part='g' normalized='g'
TokenToCanntMapper: token='{g}X3' normalized='g'
TokenToCanntMapper: NO MAPPING for 'g'
